{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b75493",
   "metadata": {},
   "source": [
    "# Nearest Neighbour Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15b1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df_sales = pd.read_excel(\"../DATA CURRENT/SALES.xlsx\")\n",
    "df_parameters = pd.read_excel(\"../DATA CURRENT/L1-PARAMETERS.xlsx\")\n",
    "\n",
    "# Merge df_parameters into df\n",
    "df = df_parameters.copy()\n",
    "\n",
    "# Define the columns to calculate stats for\n",
    "columns_to_calculate = ['Price', 'Quantity']\n",
    "\n",
    "# Create empty lists to store the results\n",
    "item_codes = []\n",
    "quoted_price_min = []\n",
    "quoted_price_max = []\n",
    "quoted_price_avg = []\n",
    "quoted_quantity_min = []\n",
    "quoted_quantity_max = []\n",
    "quoted_quantity_avg = []\n",
    "ordered_price_min = []\n",
    "ordered_price_max = []\n",
    "ordered_price_avg = []\n",
    "ordered_quantity_min = []\n",
    "ordered_quantity_max = []\n",
    "ordered_quantity_avg = []\n",
    "average_price = []\n",
    "\n",
    "# Loop through each Item Code in df_parameters\n",
    "for item_code in df_parameters['Item Code']:\n",
    "    # Filter df_sales for the current item code\n",
    "    df_item_sales = df_sales[df_sales['Item Code'] == item_code]\n",
    "    \n",
    "    # Quoted prices and quantities\n",
    "    df_quoted = df_item_sales[df_item_sales['Status'] == 'QUOTATO']\n",
    "    quoted_price_min.append(df_quoted['Price'].min())\n",
    "    quoted_price_max.append(df_quoted['Price'].max())\n",
    "    quoted_price_avg.append(df_quoted['Price'].mean())\n",
    "    quoted_quantity_min.append(df_quoted['Quantity'].min())\n",
    "    quoted_quantity_max.append(df_quoted['Quantity'].max())\n",
    "    quoted_quantity_avg.append(df_quoted['Quantity'].mean())\n",
    "    \n",
    "    # Ordered prices and quantities\n",
    "    df_ordered = df_item_sales[df_item_sales['Status'] == 'ORDINATO']\n",
    "    ordered_price_min.append(df_ordered['Price'].min())\n",
    "    ordered_price_max.append(df_ordered['Price'].max())\n",
    "    ordered_price_avg.append(df_ordered['Price'].mean())\n",
    "    ordered_quantity_min.append(df_ordered['Quantity'].min())\n",
    "    ordered_quantity_max.append(df_ordered['Quantity'].max())\n",
    "    ordered_quantity_avg.append(df_ordered['Quantity'].mean())\n",
    "    \n",
    "    # Average price across both statuses\n",
    "    avg_price = df_item_sales['Price'].mean(skipna=True)\n",
    "    average_price.append(avg_price)\n",
    "\n",
    "# Add the calculated stats to df\n",
    "df['Quoted Price Min'] = quoted_price_min\n",
    "df['Quoted Price Max'] = quoted_price_max\n",
    "df['Quoted Price Avg'] = quoted_price_avg\n",
    "df['Quoted Quantity Min'] = quoted_quantity_min\n",
    "df['Quoted Quantity Max'] = quoted_quantity_max\n",
    "df['Quoted Quantity Avg'] = quoted_quantity_avg\n",
    "df['Ordered Price Min'] = ordered_price_min\n",
    "df['Ordered Price Max'] = ordered_price_max\n",
    "df['Ordered Price Avg'] = ordered_price_avg\n",
    "df['Ordered Quantity Min'] = ordered_quantity_min\n",
    "df['Ordered Quantity Max'] = ordered_quantity_max\n",
    "df['Ordered Quantity Avg'] = ordered_quantity_avg\n",
    "df['Average Price'] = average_price\n",
    "\n",
    "# Save the resulting df to an Excel file\n",
    "df.to_excel('L1 - MASTER_DATA.xlsx', index=False)\n",
    "\n",
    "# Define parameters and target columns\n",
    "parameters = ['Layout', 'Sensing Element', 'Case Material', 'Cable Material', 'Cable Length', 'Terminal']\n",
    "target_price = 'Average Price'\n",
    "target_columns = [\n",
    "    'Item Code', 'Quoted Price Min', 'Quoted Price Max', 'Quoted Price Avg', \n",
    "    'Quoted Quantity Min', 'Quoted Quantity Max', 'Quoted Quantity Avg',\n",
    "    'Ordered Price Min', 'Ordered Price Max', 'Ordered Price Avg',\n",
    "    'Ordered Quantity Min', 'Ordered Quantity Max', 'Ordered Quantity Avg'\n",
    "]\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['Cable Length']),\n",
    "        ('cat', OneHotEncoder(), ['Layout', 'Sensing Element', 'Case Material', 'Cable Material', 'Terminal'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "\n",
    "# Create pipeline for preprocessing, polynomial features, and regression\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('poly', poly),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "X = df[parameters]\n",
    "y_price = df[target_price]\n",
    "\n",
    "# Train the model for average_price\n",
    "pipeline.fit(X, y_price)\n",
    "feature_importance_price = pipeline.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Get the feature names after preprocessing and polynomial features\n",
    "one_hot_features = pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(\n",
    "    ['Layout', 'Sensing Element', 'Case Material', 'Cable Material', 'Terminal'])\n",
    "feature_names = np.append(['Cable Length'], one_hot_features)\n",
    "poly_features = poly.get_feature_names_out(feature_names)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': poly_features,\n",
    "    'Importance': feature_importance_price\n",
    "})\n",
    "\n",
    "# Normalize the importance to get weights\n",
    "feature_importance_df['Weight'] = feature_importance_df['Importance'] / feature_importance_df['Importance'].sum()\n",
    "\n",
    "# Save as excel because too long\n",
    "feature_importance_df.to_excel('L1_feature_importance.xlsx', index=False)\n",
    "\n",
    "# Use the weights for the nearest neighbor model\n",
    "weights = feature_importance_df.set_index('Feature')['Weight'].to_dict()\n",
    "\n",
    "# Prepare the data for Nearest Neighbors using the calculated weights\n",
    "X_preprocessed = preprocessor.fit_transform(X).toarray()  # Convert sparse matrix to dense\n",
    "X_poly = poly.fit_transform(X_preprocessed)\n",
    "\n",
    "# Apply weights to the preprocessed features\n",
    "weighted_features = np.array([weights[feature] for feature in poly_features])\n",
    "X_preprocessed_weighted = X_poly * weighted_features\n",
    "\n",
    "# Fit the NearestNeighbors model\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='auto').fit(X_preprocessed_weighted)\n",
    "\n",
    "# Function to get user input\n",
    "def get_user_input(df):\n",
    "    user_input = {}\n",
    "    for param in parameters:\n",
    "        if param == 'Cable Length':\n",
    "            user_input[param] = float(input(f\"Enter {param}: \"))\n",
    "        else:\n",
    "            unique_values = df[param].unique()\n",
    "            print(f\"Select {param} from the following options: {', '.join(unique_values)}\")\n",
    "            user_input[param] = input(f\"Enter {param}: \")\n",
    "    return user_input\n",
    "\n",
    "# Get user input\n",
    "user_input = get_user_input(df)\n",
    "\n",
    "# Convert user input to DataFrame\n",
    "input_df = pd.DataFrame([user_input])\n",
    "\n",
    "# Check if the identical product exists in the dataset\n",
    "identical_product = df[\n",
    "    (df['Layout'] == user_input['Layout']) &\n",
    "    (df['Sensing Element'] == user_input['Sensing Element']) &\n",
    "    (df['Case Material'] == user_input['Case Material']) &\n",
    "    (df['Cable Material'] == user_input['Cable Material']) &\n",
    "    (df['Cable Length'] == user_input['Cable Length']) &\n",
    "    (df['Terminal'] == user_input['Terminal'])\n",
    "]\n",
    "\n",
    "if not identical_product.empty:\n",
    "    print(\"Identical product found:\")\n",
    "    print(identical_product[target_columns])\n",
    "else:\n",
    "    # Preprocess user input\n",
    "    input_preprocessed = preprocessor.transform(input_df).toarray()  # Convert sparse matrix to dense\n",
    "    input_poly = poly.transform(input_preprocessed)\n",
    "    input_preprocessed_weighted = input_poly * weighted_features\n",
    "\n",
    "    # Find the nearest neighbors\n",
    "    distances, indices = nbrs.kneighbors(input_preprocessed_weighted)\n",
    "\n",
    "    # Normalize distances to compute similarity scores\n",
    "    max_distance = np.max(distances)\n",
    "    similarity_scores = 1 - (distances / max_distance)\n",
    "\n",
    "    # Get the closest 5 products\n",
    "    closest_products = df.iloc[indices[0]][target_columns].copy()\n",
    "    closest_products['Similarity Score'] = similarity_scores[0]\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Closest 5 products with similarity scores:\")\n",
    "    print(closest_products)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
